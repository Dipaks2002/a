{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0685673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffa4132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0435fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c10db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aad67a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e97edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ae8be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1c83c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff9eea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f6fbd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet=(\"My name is Onkar Sarvade. I am in 3rd year. In TE I have learned lot of languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a6ddfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'Onkar',\n",
       " 'Sarvade',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'in',\n",
       " '3rd',\n",
       " 'year',\n",
       " '.',\n",
       " 'In',\n",
       " 'TE',\n",
       " 'I',\n",
       " 'have',\n",
       " 'learned',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'languages']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "438c525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'Onkar', 'Sarvade', '.', 'I', 'am', 'in', '3rd', 'year', '.', 'In', 'TE', 'I', 'have', 'learned', 'lot', 'of', 'languages']\n"
     ]
    }
   ],
   "source": [
    "tokens= word_tokenize(sheet)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3db0d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Onkar', 'NNP'), ('Sarvade', 'NNP'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('in', 'IN'), ('3rd', 'CD'), ('year', 'NN'), ('.', '.'), ('In', 'IN'), ('TE', 'NNP'), ('I', 'PRP'), ('have', 'VBP'), ('learned', 'VBN'), ('lot', 'NN'), ('of', 'IN'), ('languages', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "postags=pos_tag(tokens)\n",
    "print(postags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef0a2752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'where', 'by', 't', 'ain', 'y', 'whom', 'between', 'over', 'hers', 'haven', 'didn', 'shouldn', 'now', 'does', 'am', 'do', 'through', 'll', \"weren't\", 'had', 'against', \"that'll\", 'with', 'there', 'or', 'mustn', 'aren', 'did', 'who', 'her', 'they', 'his', 'below', 'than', \"hadn't\", \"hasn't\", 'once', 'doing', 'at', 'are', 'those', 'our', 'which', \"isn't\", 'wouldn', 'but', 'theirs', 'down', 'i', 'both', 'very', 's', 'been', 'after', 'she', 'from', 'hadn', 'weren', 'yourselves', \"mustn't\", 'out', 'to', \"you'll\", 'mightn', 'ours', 'here', \"needn't\", 'will', \"wouldn't\", 'this', 'm', 'him', 'their', 'nor', 'when', 'himself', 'any', 've', \"mightn't\", 'of', 'has', 'under', 'for', 'should', 'you', 'up', 'and', 'most', 'some', 'yourself', 'its', 'ourselves', 'because', 'on', 'shan', 'what', \"shan't\", 'not', \"couldn't\", \"didn't\", 'until', \"haven't\", 'into', 'themselves', 'yours', 'off', 'is', 'if', 'before', 'why', 'how', 'myself', 'again', 'ma', 'these', 'a', 'as', 'me', 'don', \"should've\", 'during', 'won', 'such', 'have', 'was', 'just', 'o', 'all', 'doesn', 'few', \"wasn't\", 'itself', 'your', 'then', \"she's\", 'herself', 'couldn', 'needn', 'about', 'in', 'further', 'can', \"aren't\", 'wasn', \"won't\", \"doesn't\", 'it', \"you're\", 'were', 'own', 'too', 'isn', 'the', 'other', 'hasn', \"you've\", 'my', 'only', \"don't\", 'having', 'while', 'we', \"shouldn't\", 'd', 're', 'an', 'be', 'same', 'he', 'so', \"you'd\", 'more', 'each', 'them', 'being', 'no', 'that', \"it's\", 'above'}\n"
     ]
    }
   ],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "718043bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'Onkar', 'Sarvade', '.', 'I', '3rd', 'year', '.', 'In', 'TE', 'I', 'learned', 'lot', 'languages']\n"
     ]
    }
   ],
   "source": [
    "li=[]\n",
    "for words in tokens:\n",
    "    if words not in stop_words:\n",
    "        li.append(words)\n",
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "708ee2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['My', 'my'], ['name', 'name'], ['Onkar', 'onkar'], ['Sarvade', 'sarvad'], ['.', '.'], ['I', 'i'], ['3rd', '3rd'], ['year', 'year'], ['.', '.'], ['In', 'in'], ['TE', 'te'], ['I', 'i'], ['learned', 'learn'], ['lot', 'lot'], ['languages', 'languag']]\n"
     ]
    }
   ],
   "source": [
    "#Stemming\n",
    "ps=PorterStemmer()\n",
    "stemlist=[]\n",
    "for words in li:\n",
    "    stemlist.append([words, ps.stem(words)])\n",
    "print(stemlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b36a064a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['My', 'My'], ['name', 'name'], ['Onkar', 'Onkar'], ['Sarvade', 'Sarvade'], ['.', '.'], ['I', 'I'], ['3rd', '3rd'], ['year', 'year'], ['.', '.'], ['In', 'In'], ['TE', 'TE'], ['I', 'I'], ['learned', 'learned'], ['lot', 'lot'], ['languages', 'language']]\n"
     ]
    }
   ],
   "source": [
    "#Lemmatizaion\n",
    "wl=WordNetLemmatizer()\n",
    "lemilist=[]\n",
    "for words in li:\n",
    "    lemilist.append([words, wl.lemmatize(words)])\n",
    "print(lemilist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bea096ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'My': 1, 'name': 1, 'Onkar': 1, 'Sarvade': 1, '.': 2, 'I': 2, '3rd': 1, 'year': 1, 'In': 1, 'TE': 1, 'learned': 1, 'lot': 1, 'languages': 1}\n"
     ]
    }
   ],
   "source": [
    "#Word Frequency\n",
    "fre=dict()\n",
    "for words in li:\n",
    "    if words in fre:\n",
    "        fre[words]+=1\n",
    "    else:\n",
    "        fre[words]=1\n",
    "print(fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e77ba0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'My': 0.06666666666666667, 'name': 0.06666666666666667, 'Onkar': 0.06666666666666667, 'Sarvade': 0.06666666666666667, '.': 0.13333333333333333, 'I': 0.13333333333333333, '3rd': 0.06666666666666667, 'year': 0.06666666666666667, 'In': 0.06666666666666667, 'TE': 0.06666666666666667, 'learned': 0.06666666666666667, 'lot': 0.06666666666666667, 'languages': 0.06666666666666667}\n"
     ]
    }
   ],
   "source": [
    "#Calculate TF for each word in li\n",
    "total_words= len(li)\n",
    "tf={}\n",
    "for word in li:\n",
    "    if word in tf:\n",
    "        tf[word]+=1/total_words\n",
    "    else:\n",
    "        tf[word]=1/total_words\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05775abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'My': 0, 'name': 0, 'Onkar': 0, 'Sarvade': 0, '.': 3.7013019741124933, 'I': 3.295836866004329, '3rd': 0, 'year': 0, 'In': 0, 'TE': 0, 'learned': 0, 'lot': 0, 'languages': 0}\n"
     ]
    }
   ],
   "source": [
    "#Calculate IDF for each ward in li\n",
    "idf={}\n",
    "num_docs=len(sheet)\n",
    "for word in li:\n",
    "    count = sum(1 for doc in sheet if word in doc)\n",
    "    idf[word]= math.log(num_docs/count) if count > 0 else 0\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1543b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
